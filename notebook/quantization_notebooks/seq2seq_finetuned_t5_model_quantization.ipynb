{
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [],
      "dockerImageVersionId": 30732,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "huGEoaJPqqqW",
        "outputId": "c4843c89-2922-45c0-902f-b2515b74f6eb"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install optimum quanto onnxruntime onnxruntime-tools onnxconverter_common -q"
      ],
      "metadata": {
        "id": "S28Ld-Weq5Nh",
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        }
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing necessary dependencies"
      ],
      "metadata": {
        "id": "VIurabT4HVxF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import onnx\n",
        "import torch\n",
        "import transformers\n",
        "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, pipeline\n",
        "from optimum.onnxruntime import ORTQuantizer, ORTModelForSeq2SeqLM\n",
        "from pathlib import Path\n",
        "from transformers.onnx import FeaturesManager\n",
        "from optimum.onnxruntime import ORTQuantizer, ORTModelForSeq2SeqLM\n",
        "from onnxruntime.quantization import quantize_dynamic, QuantType\n",
        "from onnxconverter_common import float16"
      ],
      "metadata": {
        "id": "X3XqvQ-VrB2A"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading and inferencing model finetuned model"
      ],
      "metadata": {
        "id": "zky7ynZVHf-G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fine_tuned_checkpoint = \"/content/drive/MyDrive/news_summarizer_seq2seq/finetuned_model\""
      ],
      "metadata": {
        "id": "MHqqbARnrK39"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fine_tuned_model = AutoModelForSeq2SeqLM.from_pretrained(fine_tuned_checkpoint)\n",
        "tokenizer = AutoTokenizer.from_pretrained(fine_tuned_checkpoint)"
      ],
      "metadata": {
        "id": "fSM-NCNar2vW"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fine_tuned_pipeline = pipeline(\"summarization\", model=fine_tuned_model, tokenizer=tokenizer)"
      ],
      "metadata": {
        "id": "rfqZFcP5r6ag"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fine_tuned_pipeline(\"\"\"In 2013, Kohli was ranked number one in the ICC rankings for ODI batsmen. In 2015, he achieved the summit of T20I rankings.[7] In 2018, he was ranked top Test batsman, making him the only Indian cricketer to hold the number one spot in all three formats of the game. He is the first player to score 20,000 runs in a decade. In 2020, the International Cricket Council named him the male cricketer of the decade.\"\"\")[0]['summary_text']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "KbXA4CRbsBKL",
        "outputId": "e9019de9-1560-4557-a87b-8df9d0dc8eb0"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 200, but your input_length is only 108. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=54)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Kohli is the only Indian cricketer to hold the number one spot in all three formats of the game . In 2020, the International Cricket Council named him the male cricketer of the decade .'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Converting model files in onnx format"
      ],
      "metadata": {
        "id": "0Hm8wum8IOE7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## This line below generates onnx files for seq2seq model"
      ],
      "metadata": {
        "id": "WGsq1_3aIn0o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!optimum-cli export onnx --model /content/drive/MyDrive/news_summarizer_seq2seq/finetuned_model --task seq2seq-lm-with-past --for-ort /content/drive/MyDrive/news_summarizer_seq2seq/onnx_model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zq5wCUdy_zb5",
        "outputId": "46595b0f-1d93-425b-8f7a-d61d0c5169b6",
        "scrolled": true,
        "collapsed": true
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-06-20 13:45:48.668157: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-06-20 13:45:48.668251: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-06-20 13:45:48.670249: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-06-20 13:45:50.290061: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "The option --for-ort was passed, but its behavior is now the default in the ONNX exporter and passing it is not required anymore.\n",
            "Framework not specified. Using pt to export the model.\n",
            "Using the export variant default. Available variants are:\n",
            "    - default: The default ONNX variant.\n",
            "\n",
            "***** Exporting submodel 1/3: T5Stack *****\n",
            "Using framework PyTorch: 2.3.0+cu121\n",
            "Overriding 1 configuration item(s)\n",
            "\t- use_cache -> False\n",
            "\n",
            "***** Exporting submodel 2/3: T5ForConditionalGeneration *****\n",
            "Using framework PyTorch: 2.3.0+cu121\n",
            "Overriding 1 configuration item(s)\n",
            "\t- use_cache -> True\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py:1018: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "  if causal_mask.shape[1] < attention_mask.shape[1]:\n",
            "\n",
            "***** Exporting submodel 3/3: T5ForConditionalGeneration *****\n",
            "Using framework PyTorch: 2.3.0+cu121\n",
            "Overriding 1 configuration item(s)\n",
            "\t- use_cache -> True\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/modeling_t5.py:501: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "  elif past_key_value.shape[2] != key_value_states.shape[1]:\n",
            "In-place op on output of tensor.shape. See https://pytorch.org/docs/master/onnx.html#avoid-inplace-operations-when-using-tensor-shape-in-tracing-mode\n",
            "In-place op on output of tensor.shape. See https://pytorch.org/docs/master/onnx.html#avoid-inplace-operations-when-using-tensor-shape-in-tracing-mode\n",
            "Post-processing the exported models...\n",
            "Weight deduplication check in the ONNX export requires accelerate. Please install accelerate to run it.\n",
            "The two models proto have different outputs (25 and 13 outputs). Constant outputs will be added to unify the two models outputs. This is expected for encoder-decoder models where cached cross-attention key/values are constant outputs, omitted in the model with KV cache.\n",
            "Adding a constant output for present.0.encoder.key of shape [0, 8, 1, 64] in model2.\n",
            "Adding a constant output for present.0.encoder.value of shape [0, 8, 1, 64] in model2.\n",
            "Adding a constant output for present.1.encoder.key of shape [0, 8, 1, 64] in model2.\n",
            "Adding a constant output for present.1.encoder.value of shape [0, 8, 1, 64] in model2.\n",
            "Adding a constant output for present.2.encoder.key of shape [0, 8, 1, 64] in model2.\n",
            "Adding a constant output for present.2.encoder.value of shape [0, 8, 1, 64] in model2.\n",
            "Adding a constant output for present.3.encoder.key of shape [0, 8, 1, 64] in model2.\n",
            "Adding a constant output for present.3.encoder.value of shape [0, 8, 1, 64] in model2.\n",
            "Adding a constant output for present.4.encoder.key of shape [0, 8, 1, 64] in model2.\n",
            "Adding a constant output for present.4.encoder.value of shape [0, 8, 1, 64] in model2.\n",
            "Adding a constant output for present.5.encoder.key of shape [0, 8, 1, 64] in model2.\n",
            "Adding a constant output for present.5.encoder.value of shape [0, 8, 1, 64] in model2.\n",
            "\n",
            "Validating ONNX model /content/drive/MyDrive/news_summarizer_seq2seq/onnx_model/encoder_model.onnx...\n",
            "\t-[✓] ONNX model output names match reference model (last_hidden_state)\n",
            "\t- Validating ONNX Model output \"last_hidden_state\":\n",
            "\t\t-[✓] (2, 16, 512) matches (2, 16, 512)\n",
            "\t\t-[✓] all values close (atol: 1e-05)\n",
            "\n",
            "Validating ONNX model /content/drive/MyDrive/news_summarizer_seq2seq/onnx_model/decoder_model_merged.onnx...\n",
            "\t-[✓] ONNX model output names match reference model (present.4.encoder.key, present.3.encoder.key, present.5.decoder.key, present.2.decoder.key, present.0.decoder.value, present.1.decoder.key, present.1.encoder.value, present.3.encoder.value, present.3.decoder.value, present.5.encoder.key, logits, present.0.encoder.value, present.2.encoder.value, present.1.decoder.value, present.5.decoder.value, present.4.encoder.value, present.4.decoder.key, present.0.decoder.key, present.2.decoder.value, present.5.encoder.value, present.1.encoder.key, present.3.decoder.key, present.2.encoder.key, present.0.encoder.key, present.4.decoder.value)\n",
            "\t- Validating ONNX Model output \"logits\":\n",
            "\t\t-[✓] (2, 16, 32128) matches (2, 16, 32128)\n",
            "\t\t-[✓] all values close (atol: 1e-05)\n",
            "\t- Validating ONNX Model output \"present.0.decoder.key\":\n",
            "\t\t-[✓] (2, 8, 16, 64) matches (2, 8, 16, 64)\n",
            "\t\t-[✓] all values close (atol: 1e-05)\n",
            "\t- Validating ONNX Model output \"present.0.decoder.value\":\n",
            "\t\t-[✓] (2, 8, 16, 64) matches (2, 8, 16, 64)\n",
            "\t\t-[✓] all values close (atol: 1e-05)\n",
            "\t- Validating ONNX Model output \"present.0.encoder.key\":\n",
            "\t\t-[✓] (2, 8, 16, 64) matches (2, 8, 16, 64)\n",
            "\t\t-[✓] all values close (atol: 1e-05)\n",
            "\t- Validating ONNX Model output \"present.0.encoder.value\":\n",
            "\t\t-[✓] (2, 8, 16, 64) matches (2, 8, 16, 64)\n",
            "\t\t-[✓] all values close (atol: 1e-05)\n",
            "\t- Validating ONNX Model output \"present.1.decoder.key\":\n",
            "\t\t-[✓] (2, 8, 16, 64) matches (2, 8, 16, 64)\n",
            "\t\t-[✓] all values close (atol: 1e-05)\n",
            "\t- Validating ONNX Model output \"present.1.decoder.value\":\n",
            "\t\t-[✓] (2, 8, 16, 64) matches (2, 8, 16, 64)\n",
            "\t\t-[✓] all values close (atol: 1e-05)\n",
            "\t- Validating ONNX Model output \"present.1.encoder.key\":\n",
            "\t\t-[✓] (2, 8, 16, 64) matches (2, 8, 16, 64)\n",
            "\t\t-[✓] all values close (atol: 1e-05)\n",
            "\t- Validating ONNX Model output \"present.1.encoder.value\":\n",
            "\t\t-[✓] (2, 8, 16, 64) matches (2, 8, 16, 64)\n",
            "\t\t-[✓] all values close (atol: 1e-05)\n",
            "\t- Validating ONNX Model output \"present.2.decoder.key\":\n",
            "\t\t-[✓] (2, 8, 16, 64) matches (2, 8, 16, 64)\n",
            "\t\t-[✓] all values close (atol: 1e-05)\n",
            "\t- Validating ONNX Model output \"present.2.decoder.value\":\n",
            "\t\t-[✓] (2, 8, 16, 64) matches (2, 8, 16, 64)\n",
            "\t\t-[✓] all values close (atol: 1e-05)\n",
            "\t- Validating ONNX Model output \"present.2.encoder.key\":\n",
            "\t\t-[✓] (2, 8, 16, 64) matches (2, 8, 16, 64)\n",
            "\t\t-[✓] all values close (atol: 1e-05)\n",
            "\t- Validating ONNX Model output \"present.2.encoder.value\":\n",
            "\t\t-[✓] (2, 8, 16, 64) matches (2, 8, 16, 64)\n",
            "\t\t-[✓] all values close (atol: 1e-05)\n",
            "\t- Validating ONNX Model output \"present.3.decoder.key\":\n",
            "\t\t-[✓] (2, 8, 16, 64) matches (2, 8, 16, 64)\n",
            "\t\t-[✓] all values close (atol: 1e-05)\n",
            "\t- Validating ONNX Model output \"present.3.decoder.value\":\n",
            "\t\t-[✓] (2, 8, 16, 64) matches (2, 8, 16, 64)\n",
            "\t\t-[✓] all values close (atol: 1e-05)\n",
            "\t- Validating ONNX Model output \"present.3.encoder.key\":\n",
            "\t\t-[✓] (2, 8, 16, 64) matches (2, 8, 16, 64)\n",
            "\t\t-[✓] all values close (atol: 1e-05)\n",
            "\t- Validating ONNX Model output \"present.3.encoder.value\":\n",
            "\t\t-[✓] (2, 8, 16, 64) matches (2, 8, 16, 64)\n",
            "\t\t-[✓] all values close (atol: 1e-05)\n",
            "\t- Validating ONNX Model output \"present.4.decoder.key\":\n",
            "\t\t-[✓] (2, 8, 16, 64) matches (2, 8, 16, 64)\n",
            "\t\t-[✓] all values close (atol: 1e-05)\n",
            "\t- Validating ONNX Model output \"present.4.decoder.value\":\n",
            "\t\t-[✓] (2, 8, 16, 64) matches (2, 8, 16, 64)\n",
            "\t\t-[✓] all values close (atol: 1e-05)\n",
            "\t- Validating ONNX Model output \"present.4.encoder.key\":\n",
            "\t\t-[✓] (2, 8, 16, 64) matches (2, 8, 16, 64)\n",
            "\t\t-[✓] all values close (atol: 1e-05)\n",
            "\t- Validating ONNX Model output \"present.4.encoder.value\":\n",
            "\t\t-[✓] (2, 8, 16, 64) matches (2, 8, 16, 64)\n",
            "\t\t-[x] values not close enough, max diff: 2.09808349609375e-05 (atol: 1e-05)\n",
            "\t- Validating ONNX Model output \"present.5.decoder.key\":\n",
            "\t\t-[✓] (2, 8, 16, 64) matches (2, 8, 16, 64)\n",
            "\t\t-[✓] all values close (atol: 1e-05)\n",
            "\t- Validating ONNX Model output \"present.5.decoder.value\":\n",
            "\t\t-[✓] (2, 8, 16, 64) matches (2, 8, 16, 64)\n",
            "\t\t-[✓] all values close (atol: 1e-05)\n",
            "\t- Validating ONNX Model output \"present.5.encoder.key\":\n",
            "\t\t-[✓] (2, 8, 16, 64) matches (2, 8, 16, 64)\n",
            "\t\t-[✓] all values close (atol: 1e-05)\n",
            "\t- Validating ONNX Model output \"present.5.encoder.value\":\n",
            "\t\t-[✓] (2, 8, 16, 64) matches (2, 8, 16, 64)\n",
            "\t\t-[x] values not close enough, max diff: 3.4332275390625e-05 (atol: 1e-05)\n",
            "\n",
            "Validating ONNX model /content/drive/MyDrive/news_summarizer_seq2seq/onnx_model/decoder_model_merged.onnx...\n",
            "\t-[✓] ONNX model output names match reference model (present.2.decoder.value, logits, present.5.decoder.key, present.2.decoder.key, present.0.decoder.value, present.1.decoder.key, present.4.decoder.key, present.3.decoder.key, present.5.decoder.value, present.0.decoder.key, present.1.decoder.value, present.3.decoder.value, present.4.decoder.value)\n",
            "\t- Validating ONNX Model output \"logits\":\n",
            "\t\t-[✓] (2, 1, 32128) matches (2, 1, 32128)\n",
            "\t\t-[✓] all values close (atol: 1e-05)\n",
            "\t- Validating ONNX Model output \"present.0.decoder.key\":\n",
            "\t\t-[✓] (2, 8, 17, 64) matches (2, 8, 17, 64)\n",
            "\t\t-[✓] all values close (atol: 1e-05)\n",
            "\t- Validating ONNX Model output \"present.0.decoder.value\":\n",
            "\t\t-[✓] (2, 8, 17, 64) matches (2, 8, 17, 64)\n",
            "\t\t-[✓] all values close (atol: 1e-05)\n",
            "\t- Validating ONNX Model output \"present.1.decoder.key\":\n",
            "\t\t-[✓] (2, 8, 17, 64) matches (2, 8, 17, 64)\n",
            "\t\t-[✓] all values close (atol: 1e-05)\n",
            "\t- Validating ONNX Model output \"present.1.decoder.value\":\n",
            "\t\t-[✓] (2, 8, 17, 64) matches (2, 8, 17, 64)\n",
            "\t\t-[✓] all values close (atol: 1e-05)\n",
            "\t- Validating ONNX Model output \"present.2.decoder.key\":\n",
            "\t\t-[✓] (2, 8, 17, 64) matches (2, 8, 17, 64)\n",
            "\t\t-[✓] all values close (atol: 1e-05)\n",
            "\t- Validating ONNX Model output \"present.2.decoder.value\":\n",
            "\t\t-[✓] (2, 8, 17, 64) matches (2, 8, 17, 64)\n",
            "\t\t-[✓] all values close (atol: 1e-05)\n",
            "\t- Validating ONNX Model output \"present.3.decoder.key\":\n",
            "\t\t-[✓] (2, 8, 17, 64) matches (2, 8, 17, 64)\n",
            "\t\t-[✓] all values close (atol: 1e-05)\n",
            "\t- Validating ONNX Model output \"present.3.decoder.value\":\n",
            "\t\t-[✓] (2, 8, 17, 64) matches (2, 8, 17, 64)\n",
            "\t\t-[✓] all values close (atol: 1e-05)\n",
            "\t- Validating ONNX Model output \"present.4.decoder.key\":\n",
            "\t\t-[✓] (2, 8, 17, 64) matches (2, 8, 17, 64)\n",
            "\t\t-[✓] all values close (atol: 1e-05)\n",
            "\t- Validating ONNX Model output \"present.4.decoder.value\":\n",
            "\t\t-[✓] (2, 8, 17, 64) matches (2, 8, 17, 64)\n",
            "\t\t-[✓] all values close (atol: 1e-05)\n",
            "\t- Validating ONNX Model output \"present.5.decoder.key\":\n",
            "\t\t-[✓] (2, 8, 17, 64) matches (2, 8, 17, 64)\n",
            "\t\t-[✓] all values close (atol: 1e-05)\n",
            "\t- Validating ONNX Model output \"present.5.decoder.value\":\n",
            "\t\t-[✓] (2, 8, 17, 64) matches (2, 8, 17, 64)\n",
            "\t\t-[x] values not close enough, max diff: 1.4781951904296875e-05 (atol: 1e-05)\n",
            "Validation for the model /content/drive/MyDrive/news_summarizer_seq2seq/onnx_model/decoder_model_merged.onnx raised: The maximum absolute difference between the output of the reference model and the ONNX exported model is not within the set tolerance 1e-05:\n",
            "- present.4.encoder.value: max diff = 2.09808349609375e-05\n",
            "- present.5.encoder.value: max diff = 3.4332275390625e-05\n",
            "The ONNX export succeeded with the warning: The maximum absolute difference between the output of the reference model and the ONNX exported model is not within the set tolerance 1e-05:\n",
            "- present.5.decoder.value: max diff = 1.4781951904296875e-05.\n",
            " The exported model was saved at: /content/drive/MyDrive/news_summarizer_seq2seq/onnx_model\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = ORTModelForSeq2SeqLM.from_pretrained(\"/content/drive/MyDrive/news_summarizer_seq2seq/onnx_model\")"
      ],
      "metadata": {
        "id": "CsLFCdTWCHLr"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "onnx_translation = pipeline(\"summarization\", model=model, tokenizer=tokenizer)"
      ],
      "metadata": {
        "id": "32IGsVmiChqU"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "onnx_translation(\"\"\"In 2013, Kohli was ranked number one in the ICC rankings for ODI batsmen. In 2015, he achieved the summit of T20I rankings.[7] In 2018, he was ranked top Test batsman, making him the only Indian cricketer to hold the number one spot in all three formats of the game. He is the first player to score 20,000 runs in a decade. In 2020, the International Cricket Council named him the male cricketer of the decade.\"\"\")[0]['summary_text']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "Bk_LuF36Cre4",
        "outputId": "dab6b5d5-1a2e-401a-d5b2-14636299459e"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 200, but your input_length is only 108. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=54)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Kohli is the only Indian cricketer to hold the number one spot in all three formats of the game . In 2020, the International Cricket Council named him the male cricketer of the decade .'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Quantization to float16"
      ],
      "metadata": {
        "id": "wVnE7X-iMh39"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def quantize_float(source_directory, target_directory, files_to_check):\n",
        "    existing_files = []\n",
        "    for file_name in files_to_check:\n",
        "        full_path = os.path.join(source_directory, file_name)\n",
        "        if os.path.isfile(full_path):\n",
        "            model = onnx.load(f\"{source_directory}/{file_name}\")\n",
        "            model_fp16 = float16.convert_float_to_float16(model)\n",
        "            onnx.save(model_fp16, f\"{target_directory}/{file_name}\")\n",
        "        print(\"\\n\\n\")\n",
        "        print(f\"{target_directory}/{file_name}=======>Done\")"
      ],
      "metadata": {
        "id": "_roNoziCKUQ2"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "quantize_float(\"/content/drive/MyDrive/news_summarizer_seq2seq/onnx_model\", \"/content/drive/MyDrive/news_summarizer_seq2seq/quantfloat_model\", [\"encoder_model.onnx\", \"decoder_model.onnx\", \"decoder_with_past_model.onnx\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hrqwSuwZLTpO",
        "outputId": "d98f7fb5-0198-44bc-8937-29b1e7f44895",
        "scrolled": true
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/onnxconverter_common/float16.py:43: UserWarning: the float32 number 5.337700414997926e-08 will be truncated to 1e-07\n",
            "  warnings.warn(\"the float32 number {} will be truncated to {}\".format(pos_min, min_positive_val))\n",
            "/usr/local/lib/python3.10/dist-packages/onnxconverter_common/float16.py:53: UserWarning: the float32 number -1.522520243213421e-08 will be truncated to -1e-07\n",
            "  warnings.warn(\"the float32 number {} will be truncated to {}\".format(neg_max, -min_positive_val))\n",
            "/usr/local/lib/python3.10/dist-packages/onnxconverter_common/float16.py:43: UserWarning: the float32 number 4.0038880655401954e-08 will be truncated to 1e-07\n",
            "  warnings.warn(\"the float32 number {} will be truncated to {}\".format(pos_min, min_positive_val))\n",
            "/usr/local/lib/python3.10/dist-packages/onnxconverter_common/float16.py:43: UserWarning: the float32 number 5.501541977537272e-08 will be truncated to 1e-07\n",
            "  warnings.warn(\"the float32 number {} will be truncated to {}\".format(pos_min, min_positive_val))\n",
            "/usr/local/lib/python3.10/dist-packages/onnxconverter_common/float16.py:53: UserWarning: the float32 number -2.747122174184824e-08 will be truncated to -1e-07\n",
            "  warnings.warn(\"the float32 number {} will be truncated to {}\".format(neg_max, -min_positive_val))\n",
            "/usr/local/lib/python3.10/dist-packages/onnxconverter_common/float16.py:53: UserWarning: the float32 number -9.264753941806703e-08 will be truncated to -1e-07\n",
            "  warnings.warn(\"the float32 number {} will be truncated to {}\".format(neg_max, -min_positive_val))\n",
            "/usr/local/lib/python3.10/dist-packages/onnxconverter_common/float16.py:43: UserWarning: the float32 number 6.655965023583121e-08 will be truncated to 1e-07\n",
            "  warnings.warn(\"the float32 number {} will be truncated to {}\".format(pos_min, min_positive_val))\n",
            "/usr/local/lib/python3.10/dist-packages/onnxconverter_common/float16.py:50: UserWarning: the float32 number -3.4028234663852886e+38 will be truncated to -10000.0\n",
            "  warnings.warn(\"the float32 number {} will be truncated to {}\".format(neg_min, -max_finite_val))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "/content/drive/MyDrive/news_summarizer_seq2seq/quantfloat_model/encoder_model.onnx=======>Done\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/onnxconverter_common/float16.py:53: UserWarning: the float32 number -3.401972037408996e-08 will be truncated to -1e-07\n",
            "  warnings.warn(\"the float32 number {} will be truncated to {}\".format(neg_max, -min_positive_val))\n",
            "/usr/local/lib/python3.10/dist-packages/onnxconverter_common/float16.py:43: UserWarning: the float32 number 1.6369307687114087e-08 will be truncated to 1e-07\n",
            "  warnings.warn(\"the float32 number {} will be truncated to {}\".format(pos_min, min_positive_val))\n",
            "/usr/local/lib/python3.10/dist-packages/onnxconverter_common/float16.py:53: UserWarning: the float32 number -4.141683263014784e-08 will be truncated to -1e-07\n",
            "  warnings.warn(\"the float32 number {} will be truncated to {}\".format(neg_max, -min_positive_val))\n",
            "/usr/local/lib/python3.10/dist-packages/onnxconverter_common/float16.py:53: UserWarning: the float32 number -7.063299278797786e-08 will be truncated to -1e-07\n",
            "  warnings.warn(\"the float32 number {} will be truncated to {}\".format(neg_max, -min_positive_val))\n",
            "/usr/local/lib/python3.10/dist-packages/onnxconverter_common/float16.py:43: UserWarning: the float32 number 8.396668249588402e-09 will be truncated to 1e-07\n",
            "  warnings.warn(\"the float32 number {} will be truncated to {}\".format(pos_min, min_positive_val))\n",
            "/usr/local/lib/python3.10/dist-packages/onnxconverter_common/float16.py:43: UserWarning: the float32 number 7.141355240491976e-08 will be truncated to 1e-07\n",
            "  warnings.warn(\"the float32 number {} will be truncated to {}\".format(pos_min, min_positive_val))\n",
            "/usr/local/lib/python3.10/dist-packages/onnxconverter_common/float16.py:43: UserWarning: the float32 number 5.406100456184504e-08 will be truncated to 1e-07\n",
            "  warnings.warn(\"the float32 number {} will be truncated to {}\".format(pos_min, min_positive_val))\n",
            "/usr/local/lib/python3.10/dist-packages/onnxconverter_common/float16.py:53: UserWarning: the float32 number -2.9938860279798973e-08 will be truncated to -1e-07\n",
            "  warnings.warn(\"the float32 number {} will be truncated to {}\".format(neg_max, -min_positive_val))\n",
            "/usr/local/lib/python3.10/dist-packages/onnxconverter_common/float16.py:53: UserWarning: the float32 number -4.941454534446166e-08 will be truncated to -1e-07\n",
            "  warnings.warn(\"the float32 number {} will be truncated to {}\".format(neg_max, -min_positive_val))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "/content/drive/MyDrive/news_summarizer_seq2seq/quantfloat_model/decoder_model.onnx=======>Done\n",
            "\n",
            "\n",
            "\n",
            "/content/drive/MyDrive/news_summarizer_seq2seq/quantfloat_model/decoder_with_past_model.onnx=======>Done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fine_tuned_model.config.to_json_file(\"/content/drive/MyDrive/news_summarizer_seq2seq/quantfloat_model/config.json\")"
      ],
      "metadata": {
        "id": "h-8HYUEpFqnf"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inferencing quantized float16 model"
      ],
      "metadata": {
        "id": "wPkyP39TNT94"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fp16_quantized_checkpoint = \"/content/drive/MyDrive/news_summarizer_seq2seq/quantfloat_model\""
      ],
      "metadata": {
        "id": "JijctFXaECnr"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "quantfloat_model = ORTModelForSeq2SeqLM.from_pretrained(fp16_quantized_checkpoint)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OKOh5WG4F-5q",
        "outputId": "3819795d-5c06-4536-dad8-f1767f74ad95"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Generation config file not found, using a generation config created from the model config.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "quantfloat_pipeline = pipeline(\"summarization\", model=quantfloat_model, tokenizer=tokenizer)"
      ],
      "metadata": {
        "id": "svklgMYcGEPB"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "quantfloat_pipeline(\"\"\"In 2013, Kohli was ranked number one in the ICC rankings for ODI batsmen. In 2015, he achieved the summit of T20I rankings.[7] In 2018, he was ranked top Test batsman, making him the only Indian cricketer to hold the number one spot in all three formats of the game. He is the first player to score 20,000 runs in a decade. In 2020, the International Cricket Council named him the male cricketer of the decade.\"\"\")[0]['summary_text']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "ArqfrubsGiDA",
        "outputId": "45178040-03f8-45c7-9dec-27cef66c39ff"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 200, but your input_length is only 108. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=54)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Kohli is the only Indian cricketer to hold the number one spot in all three formats of the game . In 2020, the International Cricket Council named him the male cricketer of the decade .'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Quantization to int8"
      ],
      "metadata": {
        "id": "gR6PsC4FTArB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def quantint_model(source_directory, target_directory, files_to_check):\n",
        "    existing_files = []\n",
        "    for file_name in files_to_check:\n",
        "        full_path = os.path.join(source_directory, file_name)\n",
        "        if os.path.isfile(full_path):\n",
        "          quantize_dynamic(f\"{source_directory}/{file_name}\",\n",
        "                  f\"{target_directory}/{file_name}\",\n",
        "                  weight_type=QuantType.QInt8)\n",
        "\n",
        "        print(\"\\n\\n\")\n",
        "        print(f\"{target_directory}/{file_name}=======>Done\")"
      ],
      "metadata": {
        "id": "j4nbQYlWSRLW"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "quantint_model(\"/content/drive/MyDrive/news_summarizer_seq2seq/onnx_model\", \"/content/drive/MyDrive/news_summarizer_seq2seq/quantint_model\", [\"encoder_model.onnx\", \"decoder_model.onnx\", \"decoder_with_past_model.onnx\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "swIQXoXpSdir",
        "outputId": "d6b0dc87-7f94-4b7d-f1d9-83555b160933",
        "scrolled": true
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Please consider to run pre-processing before quantization. Refer to example: https://github.com/microsoft/onnxruntime-inference-examples/blob/main/quantization/image_classification/cpu/ReadMe.md \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "/content/drive/MyDrive/news_summarizer_seq2seq/quantint_model/encoder_model.onnx=======>Done\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Please consider to run pre-processing before quantization. Refer to example: https://github.com/microsoft/onnxruntime-inference-examples/blob/main/quantization/image_classification/cpu/ReadMe.md \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "/content/drive/MyDrive/news_summarizer_seq2seq/quantint_model/decoder_model.onnx=======>Done\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Please consider to run pre-processing before quantization. Refer to example: https://github.com/microsoft/onnxruntime-inference-examples/blob/main/quantization/image_classification/cpu/ReadMe.md \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "/content/drive/MyDrive/news_summarizer_seq2seq/quantint_model/decoder_with_past_model.onnx=======>Done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the model configuration\n",
        "fine_tuned_model.config.to_json_file(\"/content/drive/MyDrive/news_summarizer_seq2seq/quantint_model/config.json\")"
      ],
      "metadata": {
        "id": "vQLyLDUZRpcA"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "quantint_checkpoint = \"/content/drive/MyDrive/news_summarizer_seq2seq/quantint_model\"\n",
        "tokenizer_checkpoint = \"/content/drive/MyDrive/news_summarizer_seq2seq/finetuned_model\""
      ],
      "metadata": {
        "id": "8C7O762HTORS"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inferencing quantized int-8 model"
      ],
      "metadata": {
        "id": "T2YbOhwX3wLG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "quantint_model = ORTModelForSeq2SeqLM.from_pretrained(quantint_checkpoint)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vHxPioobTlb8",
        "outputId": "b1524297-0dc4-4e0e-fb26-0a556decf3b9"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Generation config file not found, using a generation config created from the model config.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "quantint_pipeline = pipeline(\"summarization\", model=quantint_model, tokenizer=tokenizer)"
      ],
      "metadata": {
        "id": "WgY9-LZgTtXe"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "quantint_pipeline(\"\"\"In 2013, Kohli was ranked number one in the ICC rankings for ODI batsmen. In 2015, he achieved the summit of T20I rankings.[7] In 2018, he was ranked top Test batsman, making him the only Indian cricketer to hold the number one spot in all three formats of the game. He is the first player to score 20,000 runs in a decade. In 2020, the International Cricket Council named him the male cricketer of the decade.\"\"\")[0]['summary_text']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "cDg-qnL4T8Ox",
        "outputId": "53672145-e831-4ad7-80a1-e993ca9a280c"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 200, but your input_length is only 108. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=54)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Kohli was ranked number one in the ICC rankings for ODI batsmen . He is the first Indian player to score 20,000 runs in a decade .'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inference time comparision b/w finetuned, onnx format model,quantfloat and quantint model"
      ],
      "metadata": {
        "id": "1wPppfFEVOml"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_text = \"\"\"The rapid advancements in artificial intelligence (AI) technology\n",
        "                are revolutionizing various industries, from healthcare to finance.\n",
        "                In healthcare, AI-powered diagnostic tools are enhancing the accuracy of disease detection,\n",
        "                enabling early intervention and improving patient outcomes.\n",
        "                For instance, AI algorithms can analyze medical images\n",
        "                with greater precision than human doctors,\n",
        "                identifying abnormalities that might be missed during manual examination.\n",
        "                In finance, AI-driven algorithms are optimizing trading strategies,\n",
        "                predicting market trends, and managing risk more effectively.\n",
        "                These technologies not only increase efficiency but also reduce operational costs.\n",
        "                However, the widespread adoption of AI also raises ethical concerns,\n",
        "                such as data privacy and the potential for job displacement.\n",
        "                As AI continues to evolve, it is crucial to address these issues through thoughtful\n",
        "                regulation and by ensuring that AI systems are developed and deployed responsibly.\"\"\""
      ],
      "metadata": {
        "id": "gDOnkz4GWM7P"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "fine_tuned_pipeline(input_text)[0]['summary_text']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "id": "J7U0ff4MUAVY",
        "outputId": "ab5dd656-fc59-4201-b7f8-880723e0064a"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 200, but your input_length is only 168. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=84)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 2.41 s, sys: 20.2 ms, total: 2.43 s\n",
            "Wall time: 2.43 s\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'In healthcare, AI-powered diagnostic tools are enhancing the accuracy of disease detection . For example, AI algorithms can analyze medical images with greater precision than human doctors .'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "onnx_translation(\"\"\"In 2013, Kohli was ranked number one in the ICC rankings for ODI batsmen. In 2015, he achieved the summit of T20I rankings.[7] In 2018, he was ranked top Test batsman, making him the only Indian cricketer to hold the number one spot in all three formats of the game. He is the first player to score 20,000 runs in a decade. In 2020, the International Cricket Council named him the male cricketer of the decade.\"\"\")[0]['summary_text']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "id": "T2QWRnCQ6ibo",
        "outputId": "b852b097-97f5-4798-f57f-162366b73f2e"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 200, but your input_length is only 108. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=54)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 1.54 s, sys: 2.25 ms, total: 1.54 s\n",
            "Wall time: 1.62 s\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Kohli is the only Indian cricketer to hold the number one spot in all three formats of the game . In 2020, the International Cricket Council named him the male cricketer of the decade .'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "quantfloat_pipeline(input_text)[0]['summary_text']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "id": "fGt75-a-UogL",
        "outputId": "5739f06d-71bd-4f2c-f32e-403b9abcdd72"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 200, but your input_length is only 168. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=84)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 7.85 s, sys: 98.9 ms, total: 7.95 s\n",
            "Wall time: 8.11 s\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'In healthcare, AI-powered diagnostic tools are enhancing the accuracy of disease detection . For example, AI algorithms can analyze medical images with greater precision than human doctors .'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "quantint_pipeline(input_text)[0]['summary_text']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "id": "AbaZjlOAU9_T",
        "outputId": "8a3f8bf7-0eed-4397-e86d-475254e05d41"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 200, but your input_length is only 168. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=84)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 902 ms, sys: 2.79 ms, total: 905 ms\n",
            "Wall time: 905 ms\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'AI-powered diagnostic tools are revolutionizing various industries, from healthcare to finance . For example, AI algorithms can analyze medical images with greater precision than human doctors .'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "E6B-xr3yVEdr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}